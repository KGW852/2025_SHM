# configs/default.yaml

# experiment set
exp_name: exp1  # all, exp1, exp2...
seed: 42

# path
model:
  data_name: dongjak
  model_name: convergent_sim
  trainer: convergent_sim_trainer.py
  trainer_fn: ConvergentSimTrainer
  evaluator: convergent_sim_evaluator.py
  evaluator_fn: ConvergentSimEvaluator
  version: 1.0
  suffix: .pth
  base_dir: ./logs  # save model base dir

# train eval parameters
log_every: 1
save_every: 1

# data parameters
batch_size: 32
n_workers: 8
match_strategy: sequential  # random, sequential, pairwise

# train parameters
device: cuda
epochs: 2

loss:
  recon_loss: mae

optimizer:
  type: adam
  learning_rate: 1e-4
  weight_decay: 1e-4
  momentum: 0.9

scheduler:  # steplr, multisteplr, exponentiallr, cosineannealinglr
  type: steplr
  step_size: 5
  gamma: 0.1
  milestones: [30, 88]
  t_max: 50
  eta_min: 0

early_stopper:
  use: True
  patience: 3
  mode: min  # min, max
  min_delta: 0.0
  baseline: 0.1  # None, float

# mlflow parameters
mlflow:
  use: True
  tracking_uri: file:./logs/mlruns  # using "file:" save mlruns to local dir

# mlp parameters
mlp:
  in_dim: 1024
  in_hidden_dims: [512, 256]
  latent_dim: 128
  out_hidden_dims: [128, 256, 512]
  out_channels: 2
  out_seq_len: 512
  dropout: 0.1

# tcn parameters
tcn:
  in_channels: 2
  n_layers: 3
  filters_base: 4
  filters_factor: 2
  kernel_size: 3
  stride: 2
  dilation_base: 2
  use_batch_norm: False
  dropout: 0.0

# simsiam parameters
sim:
  in_dim: 128
  proj_hidden_dim: 64
  proj_out_dim: 64
  pred_hidden_dim: 32
  pred_out_dim: 64

# umap parameters
umap:
  n_neighbors: 15
  min_dist: 0.1
  n_components: 2
  random_state: 42
  metric: cosine

# anomaly score metric
anomaly:
  method: simsiam  # simsiam, distance, distribution
  return_thresholded_preds: True
  distribution_percentile: 99